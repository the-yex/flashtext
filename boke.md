# 🚀 重新定义Go语言高性能关键词匹配：比Regex快500倍的AC自动机实现

在处理文本分析、敏感词过滤或内容审核时，我们经常面临一个核心挑战：**如何在一个长文本中快速找到成千上万个关键词？**

传统的正则表达式（Regexp）在面对大量关键词时性能会急剧下降，而现有的部分Go语言Trie树实现又往往为了追求性能而牺牲了匹配的完整性（例如遗漏重叠词）。

今天，我想介绍一个为了解决这些问题而生的开源项目 —— **Flashtext for Go**。它不仅拥有甚至超越Trie树的性能，更重要的是，它保证了**100%的匹配完整性**，并且在内存管理上做到了极致的优化。

## 🌟 核心亮点

### 1. 极致性能：比正则快500倍
当关键词数量达到1万个时，标准的正则表达式处理大文本可能需要几十秒，而我们的库**仅需53ms**。

性能对比（10,000个关键词，MacBook M1）：

| 实现方式 | 耗时 | 性能倍数 |
| :--- | :--- | :--- |
| **Flashtext (本库)** | **0.05秒** | **1x (基准)** |
| 正则表达式 | 26.3秒 | 慢500倍 |

而且，**性能与关键词数量几乎无关**。无论你有100个关键词还是10万个关键词，匹配长文本的时间复杂度始终保持稳定（O(N)，N为文本长度）。

### 2. Zero-Alloc：几乎为零的内存分配
Go高性能编程的圣杯是 "Zero Allocation"。我们在热点代码路径上进行了深度优化：

- **核心匹配过程无内存分配**：在遍历文本进行匹配的核心循环中，如果没有命中关键词，**没有任何内存分配**。
- **预分配机制**：结果集切片和队列均采用预分配策略，避免扩容带来的GC压力。
- **内存复用**：提供对象池或复用API，让高频调用的开销降到最低。

在基准测试中，处理6MB语料仅产生**8次**堆分配（主要是结果集的底层数组扩容），这对于高并发系统来说意味着极低的GC负担。

### 3. 越用越快：首创自适应容量引擎 🧠
传统库通常使用固定的内存分配策略（要么太小导致频繁扩容，要么太大导致内存浪费）。我们引入了 **EWMA (指数加权移动平均)** 算法，让程序具有了"学习能力"。

它会自动学习你业务数据的关键词密度，动态调整内存预分配策略。

**实测数据（1000次连续调用）**：

| 阶段 | 迭代次数 | 预估容量 | 实际匹配数 | 扩容次数 |
| :--- | :--- | :--- | :--- | :--- |
| **学习期** | 第 1 次 | 215 | 200 | 1 |
| **适应期** | 第 10 次 | 383 | 200 | 0 |
| **稳定期** | 第 50-1000 次 | **423** | 200 | **0** |

**结论**：服务运行越久，内存模型越精准，最终达到 **Zero-Grow（零扩容）** 的完美状态。

### 4. 准确性：绝不遗漏任何重叠词
很多同类库（如ayoyu/flashtext）为了简化逻辑，在Trie树匹配失败后直接跳过或回退到根节点，这导致了严重的**重叠词漏报**问题。

**举例**：
文本："she runs"
关键词：["she", "he"]

- **其他库**：匹配到 "she" 后，消耗了 's', 'h', 'e'，导致内部指针无法识别出重叠的 "he"。
- **本库**：基于完整的**AC自动机（Aho-Corasick）**算法，利用失败指针（Failure Pointer）优雅地处理回溯。
  - ✅ 匹配 "she"
  - ✅ 同时也匹配 "he"

在敏感词过滤场景下，漏报是不可接受的。我们保证：**所有出现在文本中的关键词，无论是否重叠，都会被精准抓取。**

## 🛠 使用简单

API设计简洁直观，开箱即用：

```go
import "github.com/the-yex/flashtext"

func main() {
    // 1. 初始化 (thread-safe after build)
    kp := flashtext.NewKeywordProcessor(false) // case insensitive
    
    // 2. 添加关键词
    kp.AddKeyword("Big Data")
    kp.AddKeyword("Python")
    
    // 3. 匹配
    text := "I love Big Data and Python."
    matches := kp.ExtractKeywords(text)
    
    // 输出: ["Big Data", "Python"]
}
```

## 📊 适用场景

- **敏感词/违规词过滤**：必须确保不漏杀，且需要极高的吞吐量。
- **大规模文本标签提取**：从新闻或文章中根据几十万个标签库提取特征。
- **日志分析**：在海量日志流中实时匹配关键错误模式。

---

如果你的Go项目中正在受困于正则表达式的性能瓶颈，或者担心现有工具的匹配准确性，欢迎尝试这个库！

👉 **GitHub**: [Link to your repo]
⭐ **如果觉得有用，欢迎给个Star！**
