# 🧠 自适应容量引擎 (Self-Adaptive Capacity Engine)

FlashText 在 v1.1.0+ 版本引入了创新的 **"自适应容量引擎"**。这一设计使得库的内存使用和性能随着使用时间的推移而**自我进化和优化**。

## 💡 核心设计理念

传统的关键词提取库通常采用以下两种策略之一来分配结果集切片(`slice`)的容量：

1.  **保守策略**: 分配一个较小的固定初始容量（如 `make([]Match, 0, 10)`）。
    *   **缺点**: 如果匹配结果很多，会触发多次切片扩容 (`grow`) 和内存拷贝，导致 CPU 和内存开销激增。
2.  **激进策略**: 按照文本长度的一定比例分配（如 `len(text) / 5`）。
    *   **缺点**: 对于关键词稀疏的文本，会造成巨大的内存浪费。

**FlashText 采用了一种全新的、基于统计学的动态反馈机制。**

## ⚙️ 工作原理

引擎核心包含以下几个组件：

### 1. 密度统计器 (`Density Stats`)

我们在后台维护了一个轻量级的统计模块，实时计算 **"关键词匹配密度" (Match Density)**。

$$
Density = \frac{\text{Matches Count}}{\text{Runes Count}}
$$

即：平均每个字符包含多少个关键词匹配。

### 2. 指数加权移动平均 (EWMA)

为了避免单次异常数据的干扰（例如突然处理一篇全是关键词的垃圾文本），我们使用 **EWMA (Exponential Weighted Moving Average)** 算法来平滑更新全局密度：

```go
NewDensity = α * CurrentDensity + (1 - α) * OldDensity
```

*   **α (Alpha)**: 平滑因子（默认 0.2）。
    *   值越大，对新数据越敏感（适应快，但可能抖动）。
    *   值越小，历史权重越大（更稳定，但适应慢）。

这意味着系统不仅通过当前样本学习，还保留了历史经验，能够智能地“预测”下一篇文本可能包含的关键词数量。

### 3. 写时复制与无锁更新

为了保证极致的并发性能，统计数据的更新通过 **原子操作 (Atomic CAS)** 进行。读取操作是无锁的 (`Look-free`)，对提取主流程的性能影响几乎为零。

### 4. 智能预分配

在每次执行 `ExtractKeywords` 时，引擎会根据当前学习到的 `Density` 智能计算所需的切片容量：

```go
// 智能预估容量
Capacity = len(Text) * Density
```

*   **随着运行时间的增长**: `Density` 值会越来越精准地逼近真实业务场景的平均值。
*   **结果**: 切片分配刚刚好。既没有扩容的开销，也没有多余的内存浪费。

## 📊 参数详解

| 参数 | 默认值 | 含义 | 调整建议 |
| :--- | :--- | :--- | :--- |
| **Alpha** | `0.2` | EWMA 平滑因子 | **增大**: 如果你的业务场景关键词密度变化剧烈<br>**减小**: 如果业务场景非常稳定 |
| **Buffer** | `512` | 统计更新缓冲区大小 | 不需要调整，仅防止高并发下阻塞统计 |
| **Min Cap** | `16` | 最小预分配容量 | 兜底值，防止小文本分配过小 |
| **Max Cap** | `4096` | 最大初始分配容量 | 防止异常大文本导致一次性分配过多内存 |

## 🚀 性能收益

这个设计带来了显著的性能收益，特别是在**长期运行的服务**中：

1.  **越用越快**: 随着处理的请求变多，内存分配策略越来越精准。
2.  **Zero-Grow**: 在理想状态下，切片扩容次数降为 **0**。
3.  **GC 友好**: 减少了大量临时的切片数组垃圾，显著降低 GC 压力。

### 示例数据

假设处理 1000 字符的文本，实际包含 20 个关键词：

| 阶段 | 预估密度 | 初始分配容量 | 切片扩容次数 | 内存浪费 |
| :--- | :--- | :--- | :--- | :--- |
| **冷启动** | 0 (默认) | 16 (Min) | **1-2次** | 无 |
| **学习中** | 0.01 | 10 | **1次** | 无 |
| **稳定期** | 0.02 | 20 | **0次** (完美!) | **0** |

---

> **注意**: 这是一个后台自适应过程，用户无需手动干预。您只需像往常一样使用 API，剩下的交给引擎自动优化。
